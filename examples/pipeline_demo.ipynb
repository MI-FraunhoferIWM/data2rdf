{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Download Chowlk as submodule and install the package using pip "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing /root/2023/data2rdf\n",
            "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25hCollecting beautifulsoup4==4.11.2\n",
            "  Using cached beautifulsoup4-4.11.2-py3-none-any.whl (129 kB)\n",
            "Requirement already satisfied: chardet in /usr/lib/python3/dist-packages (from data2rdf==0.1.4) (4.0.0)\n",
            "Requirement already satisfied: openpyxl in /usr/local/lib/python3.10/dist-packages (from data2rdf==0.1.4) (3.0.10)\n",
            "Collecting pandas==1.1.5\n",
            "  Using cached pandas-1.1.5-cp310-cp310-linux_x86_64.whl\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.10/dist-packages (from data2rdf==0.1.4) (0.20.0)\n",
            "Requirement already satisfied: rdflib in /usr/local/lib/python3.10/dist-packages (from data2rdf==0.1.4) (6.2.0)\n",
            "Collecting sqlalchemy==1.4.46\n",
            "  Downloading SQLAlchemy-1.4.46-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tables in /usr/local/lib/python3.10/dist-packages (from data2rdf==0.1.4) (3.7.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4==4.11.2->data2rdf==0.1.4) (2.3.2.post1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/lib/python3/dist-packages (from pandas==1.1.5->data2rdf==0.1.4) (2022.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.10/dist-packages (from pandas==1.1.5->data2rdf==0.1.4) (2.8.2)\n",
            "Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.10/dist-packages (from pandas==1.1.5->data2rdf==0.1.4) (1.23.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy==1.4.46->data2rdf==0.1.4) (1.1.2)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.10/dist-packages (from openpyxl->data2rdf==0.1.4) (1.1.0)\n",
            "Requirement already satisfied: isodate in /usr/local/lib/python3.10/dist-packages (from rdflib->data2rdf==0.1.4) (0.6.1)\n",
            "Requirement already satisfied: pyparsing in /usr/lib/python3/dist-packages (from rdflib->data2rdf==0.1.4) (2.4.7)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from rdflib->data2rdf==0.1.4) (67.3.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tables->data2rdf==0.1.4) (21.3)\n",
            "Requirement already satisfied: numexpr>=2.6.2 in /usr/local/lib/python3.10/dist-packages (from tables->data2rdf==0.1.4) (2.8.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.7.3->pandas==1.1.5->data2rdf==0.1.4) (1.16.0)\n",
            "Building wheels for collected packages: data2rdf\n",
            "  Building wheel for data2rdf (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Created wheel for data2rdf: filename=data2rdf-0.1.4-py3-none-any.whl size=779245 sha256=850b5b354a64edf787326efbb05c2220118c96244d6d788b4685be18fcaa94c3\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-8aqk1y9p/wheels/63/77/ba/e2b1cfbd920f8dd47039dbebb3329a0aae3ac74dc0b281c324\n",
            "Successfully built data2rdf\n",
            "Installing collected packages: sqlalchemy, beautifulsoup4, pandas, data2rdf\n",
            "  Attempting uninstall: sqlalchemy\n",
            "    Found existing installation: SQLAlchemy 1.4.40\n",
            "    Uninstalling SQLAlchemy-1.4.40:\n",
            "      Successfully uninstalled SQLAlchemy-1.4.40\n",
            "  Attempting uninstall: beautifulsoup4\n",
            "    Found existing installation: beautifulsoup4 4.11.1\n",
            "    Uninstalling beautifulsoup4-4.11.1:\n",
            "      Successfully uninstalled beautifulsoup4-4.11.1\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 1.5.2\n",
            "    Uninstalling pandas-1.5.2:\n",
            "      Successfully uninstalled pandas-1.5.2\n",
            "  Attempting uninstall: data2rdf\n",
            "    Found existing installation: data2rdf 0.1.4\n",
            "    Uninstalling data2rdf-0.1.4:\n",
            "      Successfully uninstalled data2rdf-0.1.4\n",
            "Successfully installed beautifulsoup4-4.11.2 data2rdf-0.1.4 pandas-1.1.5 sqlalchemy-1.4.46\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.0.1\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!git submodule update --init --recursive\n",
        "!pip install .."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Load packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "from data2rdf.cli.abox_conversion import run_abox_pipeline_for_folder \n",
        "from data2rdf.annotation_pipeline import AnnotationPipeline\n",
        "import warnings\n",
        "import os\n",
        "warnings.filterwarnings('ignore')\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# CSV Example"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Following is a sample of running the pipeline which demonstrates the required input files.\n",
        "These include:\n",
        "- The raw **data**\n",
        "- a **method graph** which defines the abox in the experiment's scope; It is initially a .drawio that defines the relationship among entities in the data and their properties; Please refer to [this tutorial](https://data2rdf.readthedocs.io/en/latest/workflow.html#abox-skeleton) on the complete process of creating a method graph\n",
        "- a [**mapping**](https://data2rdf.readthedocs.io/en/latest/workflow.html#data-method-mapping) is required to associates entities in the data with their equivalent entity within the method graph \n",
        "\n",
        "There are a number of intermediate files created within the pipeline:\n",
        "- `run_abox_pipeline_for_folder` creates a .ttl file of the defined abox\n",
        "\n",
        "Finally, the pipeline creates an rdf graph of the column data "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Of 29 data individuals, 13 were successfully mapped to the method. See the data.mapping-result.xlsx file for mapping results.\n"
          ]
        }
      ],
      "source": [
        "working_folder = os.path.join(\"../\" ,\"tests\", \"csv_pipeline_test\")\n",
        "\n",
        "abox_folder_path = os.path.join(working_folder,\"input\" ,  \"method-graph\")\n",
        "run_abox_pipeline_for_folder(abox_folder_path)\n",
        "\n",
        "output_folder = os.path.join(working_folder,\"output\")\n",
        "template = os.path.join(abox_folder_path, \"tensile_test_method_v6\",\"tensile_test_method_v6.mod.ttl\")\n",
        "mapping_file = os.path.join(working_folder,\"input\" , \"mapping\" ,\"tensile_test_mapping.xlsx\")\n",
        "raw_data = os.path.join(working_folder, \"input\" , \"data\" ,\"DX56_D_FZ2_WR00_43.TXT\")\n",
        "\n",
        "parser = \"csv\"\n",
        "parser_args = {\n",
        "      \"header_sep\":\"\\t\",\n",
        "      \"column_sep\":\"\\t\",\n",
        "      \"header_length\":20\n",
        "   }\n",
        "\n",
        "pipeline = AnnotationPipeline(\n",
        "    raw_data,\n",
        "    parser,\n",
        "    parser_args,\n",
        "    template,\n",
        "    mapping_file,\n",
        "    output_folder,\n",
        "    data_download_iri = \"https://127.0.0.1/id\",\n",
        ")\n",
        "\n",
        "pipeline.run_pipeline()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "merged_graph.ttl\n",
            "DX56_D_FZ2_WR00_43.generic.xlsx\n",
            ".gitkeep\n",
            "DX56_D_FZ2_WR00_43.metadata.ttl\n",
            "DX56_D_FZ2_WR00_43.abox.ttl\n",
            "DX56_D_FZ2_WR00_43.mapping.ttl\n",
            "DX56_D_FZ2_WR00_43.mapping-result.xlsx\n",
            "DX56_D_FZ2_WR00_43.datastorage.hdf5\n"
          ]
        }
      ],
      "source": [
        "for file in os.listdir(output_folder):\n",
        "    print(file)\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# The final complete graph including data graph, mapping graph and process graph can be used as rdflib object or exported as ttl.\n",
        "## The ttl export can be used as input for the DSMS or any triplstore."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "475\n"
          ]
        }
      ],
      "source": [
        "pipeline = AnnotationPipeline(\n",
        "    raw_data,\n",
        "    parser,\n",
        "    parser_args,\n",
        "    template,\n",
        "    mapping_file,\n",
        "    output_folder,\n",
        ")\n",
        "\n",
        "pipeline.create_output() #set all paths but don't run the pipeline (since it was run in the block before)\n",
        "\n",
        "g = pipeline.export_graph()\n",
        "print(len(g))\n",
        "pipeline.export_ttl(os.path.join(output_folder, 'merged_graph.ttl'))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Excel parser example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Of 49 data individuals, 1 were successfully mapped to the method. See the data.mapping-result.xlsx file for mapping results.\n"
          ]
        }
      ],
      "source": [
        "working_folder = os.path.join(\"../\" ,\"tests\", \"xls_pipeline_test\")\n",
        "abox_folder_path = os.path.join(working_folder,\"input\" ,  \"method-graph\")\n",
        "run_abox_pipeline_for_folder(abox_folder_path)\n",
        "\n",
        "output_folder = os.path.join(working_folder,\"output\")\n",
        "template = os.path.join(abox_folder_path, \"tensile_test_method_v6\",\"tensile_test_method_v6.mod.ttl\")\n",
        "mapping_file = os.path.join(working_folder, \"input\" , \"mapping\",\"mapping.xlsx\")\n",
        "raw_data = os.path.join(working_folder,\"input\" , \"data\" ,\"AFZ1-Fz-S1Q.xlsm\")\n",
        "location_mapping = os.path.join(working_folder, \"input\" , \"mapping\" ,\"location_mapping.xlsx\")\n",
        "\n",
        "parser = \"excel\"\n",
        "parser_args = {\n",
        "    \"location_mapping_f_path\":location_mapping,\n",
        "   }\n",
        "\n",
        "pipeline = AnnotationPipeline(\n",
        "    raw_data,\n",
        "    parser,\n",
        "    parser_args,\n",
        "    template,\n",
        "    mapping_file,\n",
        "    output_folder,\n",
        "    base_iri = \"http://www.test4.de\"\n",
        ")\n",
        "\n",
        "pipeline.run_pipeline()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.16"
    },
    "vscode": {
      "interpreter": {
        "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
